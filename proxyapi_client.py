import os
from typing import List, Dict, Optional

import anthropic
from dotenv import load_dotenv
from openai import OpenAI

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞
load_dotenv()


class ProxyAPIClient:
    """
    –ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å OpenAI Chat Completions API –∏ –¥—É–º–∞—é—â–µ–π –º–æ–¥–µ–ª—å—é Anthropic —á–µ—Ä–µ–∑ proxyapi.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞.
    """

    def __init__(
        self,
        api_key: Optional[str] = None,
        model: str = "gpt-3.5-turbo",
        provider: str = "openai",
        temperature: float = 0.7,
        max_tokens: int = 1000,
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å proxyapi.

        Args:
            api_key: API –∫–ª—é—á OpenAI/Anthropic. –ï—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω, –±–µ—Ä–µ—Ç—Å—è –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è.
            model: –ú–æ–¥–µ–ª—å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é gpt-3.5-turbo)
            provider: "openai" (–æ–±—ã—á–Ω–∞—è) –∏–ª–∏ "anthropic" (–¥—É–º–∞—é—â–∞—è)
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (0.0-1.0)
            max_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ
        """
        self.provider = provider
        self.model = model
        self.temperature = temperature
        self.max_tokens = max_tokens
        self.system_prompt: Optional[str] = None
        self.messages: List[Dict[str, str]] = []
        self.last_thinking_text: Optional[str] = None

        # –ö–ª—é—á–∏
        openai_key = api_key or os.getenv("OPENAI_API_KEY")
        anthropic_key = api_key or os.getenv("OPENAI_API_KEY")

        # –ö–ª–∏–µ–Ω—Ç—ã
        if provider == "anthropic":
            if not anthropic_key:
                raise ValueError("API –∫–ª—é—á Anthropic –Ω–µ –Ω–∞–π–¥–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ OPENAI_API_KEY –∏–ª–∏ –ø–µ—Ä–µ–¥–∞–π—Ç–µ api_key.")
            self.anthropic_client = anthropic.Anthropic(
                api_key=anthropic_key,
                base_url=os.getenv("ANTHROPIC_BASE_URL", "https://api.proxyapi.ru/anthropic"),
                timeout=60,
            )
            self.openai_client = None
        else:
            if not openai_key:
                raise ValueError("API –∫–ª—é—á OpenAI –Ω–µ –Ω–∞–π–¥–µ–Ω. –£–∫–∞–∂–∏—Ç–µ –µ–≥–æ –≤ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä–µ –∏–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ OPENAI_API_KEY.")
            self.openai_client = OpenAI(
                api_key=openai_key,
                base_url=os.getenv("OPENAI_BASE_URL", "https://api.proxyapi.ru/openai/v1"),
            )
            self.anthropic_client = None

    def add_message(self, role: str, content: str) -> None:
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞.

        Args:
            role: –†–æ–ª—å –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è ('user', 'assistant', 'system')
            content: –¢–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
        """
        self.messages.append({"role": role, "content": content})

    def send_message(self, message: str, system_prompt: Optional[str] = None) -> tuple[str, int]:
        """
        –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –∏ –ø–æ–ª—É—á–∞–µ—Ç –æ—Ç–≤–µ—Ç –æ—Ç AI —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.

        Args:
            message: –°–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            system_prompt: –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏)

        Returns:
            –ö–æ—Ä—Ç–µ–∂ (–æ—Ç–≤–µ—Ç –æ—Ç AI, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤)
        """
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç, –µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω
        if system_prompt and not self.system_prompt:
            self.set_system_prompt(system_prompt)

        # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        self.add_message("user", message)

        try:
            if self.provider == "anthropic":
                response = self._send_anthropic()

                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏—è –∏ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç
                thinking_blocks = []
                text_blocks = []

                for block in response.content:
                    if hasattr(block, 'type'):
                        if block.type == "thinking":
                            # –£ ThinkingBlock –∞—Ç—Ä–∏–±—É—Ç –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è 'thinking', –∞ –Ω–µ 'text'
                            thinking_blocks.append(block.thinking)
                        elif block.type == "text":
                            text_blocks.append(block.text)

                self.last_thinking_text = "\n".join(thinking_blocks) if thinking_blocks else None
                ai_response = "".join(text_blocks)

                if not ai_response:
                    ai_response = "‚ö†Ô∏è –ü–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç Claude"

                # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è Anthropic
                print(f"DEBUG: Anthropic response type: {type(response)}")
                print(f"DEBUG: Anthropic response dir: {[attr for attr in dir(response) if not attr.startswith('_')]}")
                usage = getattr(response, 'usage', None)
                print(f"DEBUG: Anthropic usage object: {usage}")
                tokens_used = 0
                if usage:
                    print(f"DEBUG: Anthropic usage dir: {[attr for attr in dir(usage) if not attr.startswith('_')]}")
                    # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –ø–æ–ª—è –¥–ª—è —Ç–æ–∫–µ–Ω–æ–≤
                    output_tokens = getattr(usage, 'output_tokens', 0)
                    total_tokens = getattr(usage, 'total_tokens', 0)
                    input_tokens = getattr(usage, 'input_tokens', 0)
                    print(f"DEBUG: Anthropic usage fields - output: {output_tokens}, total: {total_tokens}, input: {input_tokens}")

                    tokens_used = output_tokens or total_tokens or (input_tokens + output_tokens)
                    print(f"DEBUG: Anthropic calculated tokens: {tokens_used}")

                # –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ü–µ–Ω–∫—É, –µ—Å–ª–∏ —Ç–æ–∫–µ–Ω—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∏–∑ API
                if tokens_used == 0 and ai_response:
                    # –ë–æ–ª–µ–µ —Ç–æ—á–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –¥–ª—è Anthropic (–æ–±—ã—á–Ω–æ 1 —Ç–æ–∫–µ–Ω = ~4 —Å–∏–º–≤–æ–ª–∞)
                    tokens_used = max(1, len(ai_response) // 4)
                    print(f"DEBUG: Anthropic tokens estimated: {tokens_used} (from {len(ai_response)} chars)")
                elif tokens_used == 0:
                    # –ï—Å–ª–∏ –¥–∞–∂–µ –æ—Ç–≤–µ—Ç–∞ –Ω–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                    tokens_used = 1
                    print(f"DEBUG: Anthropic tokens set to minimum: {tokens_used}")

            else:
                response = self._send_openai()
                self.last_thinking_text = None
                ai_response = response.choices[0].message.content

                # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è OpenAI
                print(f"DEBUG: OpenAI response type: {type(response)}")
                print(f"DEBUG: OpenAI response dir: {[attr for attr in dir(response) if not attr.startswith('_')]}")
                usage = getattr(response, 'usage', None)
                print(f"DEBUG: OpenAI usage object: {usage}")
                tokens_used = 0
                if usage:
                    print(f"DEBUG: OpenAI usage dir: {[attr for attr in dir(usage) if not attr.startswith('_')]}")
                    total_tokens = getattr(usage, 'total_tokens', 0)
                    completion_tokens = getattr(usage, 'completion_tokens', 0)
                    prompt_tokens = getattr(usage, 'prompt_tokens', 0)
                    print(f"DEBUG: OpenAI usage fields - total: {total_tokens}, completion: {completion_tokens}, prompt: {prompt_tokens}")

                    tokens_used = total_tokens or completion_tokens or (prompt_tokens + completion_tokens)
                    print(f"DEBUG: OpenAI calculated tokens: {tokens_used}")

                # –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ü–µ–Ω–∫—É, –µ—Å–ª–∏ —Ç–æ–∫–µ–Ω—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∏–∑ API
                if tokens_used == 0 and ai_response:
                    # OpenAI —Ç–æ–∫–µ–Ω—ã: –ø—Ä–∏–º–µ—Ä–Ω–æ 1 —Ç–æ–∫–µ–Ω = 0.75 —Å–ª–æ–≤–∞ –∏–ª–∏ 4 —Å–∏–º–≤–æ–ª–∞
                    tokens_used = max(1, len(ai_response) // 4)
                    print(f"DEBUG: OpenAI tokens estimated: {tokens_used} (from {len(ai_response)} chars)")
                elif tokens_used == 0:
                    # –ï—Å–ª–∏ –¥–∞–∂–µ –æ—Ç–≤–µ—Ç–∞ –Ω–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                    tokens_used = 1
                    print(f"DEBUG: OpenAI tokens set to minimum: {tokens_used}")

            # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç AI –≤ –∏—Å—Ç–æ—Ä–∏—é
            self.add_message("assistant", ai_response)

            # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º —á—Ç–æ tokens_used —ç—Ç–æ int –∏ –º–∏–Ω–∏–º—É–º 1
            tokens_used = max(1, int(tokens_used))
            print(f"üîç FINAL: Returning tokens_used = {tokens_used} (type: {type(tokens_used)})")

            return ai_response, tokens_used

        except Exception as e:
            error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ API ({self.provider}): {str(e)}"
            # –£–¥–∞–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, —Ç–∞–∫ –∫–∞–∫ –∑–∞–ø—Ä–æ—Å –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω
            if self.messages and self.messages[-1]["role"] == "user":
                self.messages.pop()
            return error_msg, 0

    def clear_history(self) -> None:
        """–û—á–∏—â–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π."""
        self.messages = []

    def get_history(self) -> List[Dict[str, str]]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π.

        Returns:
            –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ [{"role": "user", "content": "text"}, ...]
        """
        return self.messages.copy()

    def set_system_prompt(self, prompt: str) -> None:
        """
        –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç. –ó–∞–º–µ–Ω—è–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –∏–ª–∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π.

        Args:
            prompt: –¢–µ–∫—Å—Ç —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
        """
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –∏ —É–±–∏—Ä–∞–µ–º –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
        self.system_prompt = prompt
        self.messages = [msg for msg in self.messages if msg["role"] != "system"]

    def _openai_messages(self) -> List[Dict[str, str]]:
        """–ì–æ—Ç–æ–≤–∏–º —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ OpenAI."""
        msgs = self.messages.copy()
        if self.system_prompt:
            msgs = [{"role": "system", "content": self.system_prompt}] + msgs
        return msgs

    def _send_openai(self):
        """–ó–∞–ø—Ä–æ—Å –∫ OpenAI."""
        if not self.openai_client:
            raise ValueError("–ö–ª–∏–µ–Ω—Ç OpenAI –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")

        return self.openai_client.chat.completions.create(
            model=self.model,
            messages=self._openai_messages(),
            temperature=self.temperature,
            max_completion_tokens=self.max_tokens,
        )

    def _anthropic_messages(self) -> List[Dict[str, object]]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –≤ —Ñ–æ—Ä–º–∞—Ç Anthropic."""
        converted = []
        for msg in self.messages:
            if msg["role"] == "system":
                continue
            if msg["role"] not in ("user", "assistant"):
                continue
            converted.append(
                {
                    "role": msg["role"],
                    "content": [{"type": "text", "text": msg["content"]}],
                }
            )
        return converted

    def _send_anthropic(self):
        """–ó–∞–ø—Ä–æ—Å –∫ Anthropic (–¥—É–º–∞—é—â–∞—è –º–æ–¥–µ–ª—å)."""
        if not self.anthropic_client:
            raise ValueError("–ö–ª–∏–µ–Ω—Ç Anthropic –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")

        # –î–ª—è –º–æ–¥–µ–ª–µ–π —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º –º—ã—à–ª–µ–Ω–∏–µ–º –≤–∫–ª—é—á–∞–µ–º thinking
        params = {
            "model": self.model,
            "max_tokens": self.max_tokens,
            "messages": self._anthropic_messages(),
        }

        # –î–æ–±–∞–≤–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
        if self.system_prompt:
            params["system"] = self.system_prompt

        # –î–ª—è Sonnet 4.5 –≤–∫–ª—é—á–∞–µ–º extended thinking
        if "sonnet-4-5" in self.model or "sonnet-4.5" in self.model:
            # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ max_tokens –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è thinking
            # budget_tokens –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –º–µ–Ω—å—à–µ max_tokens
            # –û—Å—Ç–∞–≤–ª—è–µ–º –º–∏–Ω–∏–º—É–º 512 —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –æ—Ç–≤–µ—Ç–∞
            if self.max_tokens < 1536:  # –ú–∏–Ω–∏–º—É–º –¥–ª—è thinking (1024) + –æ—Ç–≤–µ—Ç (512)
                # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º max_tokens –¥–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–≥–æ
                params["max_tokens"] = 2048
                budget_tokens = 1024
                print(f"‚ö†Ô∏è ANTHROPIC: max_tokens —É–≤–µ–ª–∏—á–µ–Ω –¥–æ {params['max_tokens']} –¥–ª—è extended thinking")
            else:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º 2/3 –æ—Ç max_tokens –¥–ª—è thinking, 1/3 –¥–ª—è –æ—Ç–≤–µ—Ç–∞
                budget_tokens = min(1024, int(self.max_tokens * 0.66))
                print(f"‚ÑπÔ∏è ANTHROPIC: budget_tokens —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ {budget_tokens} (max_tokens: {self.max_tokens})")
            
            params["thinking"] = {"type": "enabled", "budget_tokens": budget_tokens}

        return self.anthropic_client.messages.create(**params)
